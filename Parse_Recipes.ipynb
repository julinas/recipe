{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from textblob import Word\n",
    "from spacy.symbols import *\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from word2number import w2n\n",
    "from fractions import Fraction\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Get_Recipes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word categories used for parsing\n",
    "\n",
    "food = Word('food')\n",
    "food_syn1 = food.get_synsets()[0] #Synset('food.n.01')\n",
    "food_syn2 = food.get_synsets()[1] #Synset('food.n.02')\n",
    "food_syn3 =  Word('oil').get_synsets()[0] #Synset('oil.n.01')\n",
    "\n",
    "quant_syn1 = Word('mass_unit').get_synsets()[0] #Synset('mass_unit.n.01')\n",
    "quant_syn2 = Word('containerful').get_synsets()[0] #Synset('containerful.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num(word):\n",
    "    neighbor = word\n",
    "    amount = 0\n",
    "    while neighbor.like_num:\n",
    "        try:\n",
    "            amount += float(Fraction(str(neighbor.text)))\n",
    "        except:\n",
    "            if amount == 0:\n",
    "                amount += float(w2n.word_to_num(str(neighbor.text)))\n",
    "        neighbor = neighbor.nbor(-1)\n",
    "    return amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ingredient(sent):\n",
    "    ingredient = {\"amount\": 0, \"unit\": None}\n",
    "    ingredient_word = None\n",
    "    ing_likelihood = 0\n",
    "    for word in sent:\n",
    "        word_ = Word(word.text)\n",
    "        synsets = word_.get_synsets(pos=wn.NOUN)\n",
    "        if (len(synsets) > 0):\n",
    "            wordset = set([])\n",
    "            for synset in synsets:\n",
    "                wordset.update([i for i in synset.closure(lambda s:s.hypernyms())])\n",
    "            # get ingredient\n",
    "            if (food_syn1 in wordset or food_syn2 in wordset or food_syn3 in wordset) and quant_syn2 not in wordset:\n",
    "#                     likelihood = 1.0/len(synsets)\n",
    "#                     if (ingredient is None or likelihood > ing_likelihood) and \\\n",
    "#                         (word.tag_ == \"NN\" or word.tag_ == \"NNS\"):\n",
    "                if (word.tag_ == \"NN\" or word.tag_ == \"NNS\"):\n",
    "                    ingredient_word = word\n",
    "#                         ing_likelihood = likelihood\n",
    "\n",
    "            # get quantity unit\n",
    "            if (quant_syn1 in wordset or quant_syn2 in wordset):\n",
    "                ingredient[\"unit\"] = word_.singularize()\n",
    "                # get quantity\n",
    "                neighbor = word.nbor(-1)\n",
    "                ingredient[\"amount\"] = get_num(neighbor)\n",
    "                        \n",
    "    # adjectives\n",
    "    ingredient[\"descript\"] = []\n",
    "    try:\n",
    "        ingredient[\"name\"] = ingredient_word.lemma_\n",
    "        for child in ingredient_word.children:\n",
    "            if child.pos_ == \"ADJ\":\n",
    "                ingredient[\"descript\"].append(child.lemma_)\n",
    "            elif ingredient[\"amount\"] == 0:\n",
    "                if (child.like_num):\n",
    "                    ingredient[\"amount\"] = get_num(child)                    \n",
    "\n",
    "        # remove likelihood key\n",
    "        return ingredient\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ingredient_list(text):\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    text_list = text.split(\"\\n\")\n",
    "    ingredients_set = {}\n",
    "    for text in text_list:\n",
    "        if (type(text).__name__ == \"str\"):\n",
    "            text = unicode(text, 'utf-8')\n",
    "        doc = nlp(text)\n",
    "        for sent in doc.sents:\n",
    "            ingredient = get_ingredient(sent)\n",
    "            if ingredient != None:\n",
    "                ingredients_set[Word(ingredient[\"name\"])] = ingredient\n",
    "            \n",
    "    return ingredients_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_match(text, ingredients_set):\n",
    "    if (text in ingredients_set):\n",
    "        return text\n",
    "    \n",
    "    ing1 = Word(text).get_synsets(pos=wn.NOUN)\n",
    "    if len(ing1) > 0:\n",
    "        for ingredient in ingredients_set:\n",
    "            ing2 = Word(ingredient).get_synsets(pos=wn.NOUN)\n",
    "            if len(ing2) > 0:\n",
    "                if ing1[0].path_similarity(ing2[0]) > 0.3:\n",
    "                    return ingredient\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_heat(word):\n",
    "    if (word.pos_ == \"PUNCT\"):\n",
    "        return None\n",
    "    text = word.text\n",
    "    match = None\n",
    "    hasHeat = False\n",
    "    \n",
    "    heat_keywords = ['celsius', 'c', 'fahrenheit', 'f', 'heat', 'temperature']\n",
    "    if (text in heat_keywords):\n",
    "        hasHeat = True\n",
    "    \n",
    "    word_ = Word(text)\n",
    "    text_syn = Word(text).get_synsets()\n",
    "    if len(text_syn) > 0:\n",
    "        loop1 = True\n",
    "        for keyword in heat_keywords:\n",
    "            if loop1 == False:\n",
    "                break\n",
    "            keyword_syn = Word(keyword).get_synsets()\n",
    "            if len(keyword_syn) > 0:\n",
    "                loop2 = True\n",
    "                for syn1 in text_syn:\n",
    "                    if loop2 == False:\n",
    "                        break\n",
    "                    for syn2 in keyword_syn:\n",
    "                        if syn1.path_similarity(syn2) >= 0.8:\n",
    "                            hasHeat = True\n",
    "                            match = keyword\n",
    "                            loop1 = False\n",
    "                            loop2 = False\n",
    "                            break\n",
    "                            \n",
    "    if hasHeat == True:\n",
    "        if match == \"temperature\":\n",
    "            for child in word.children:\n",
    "                if child.lemma_ == \"room\":\n",
    "                    return \"no\"\n",
    "        elif match == \"heat\":\n",
    "            for child in word.children:\n",
    "                if child.lemma_ == \"high\":\n",
    "                    return \"high\"\n",
    "                elif child.lemma_ == \"medium\":\n",
    "                    return \"medium\"\n",
    "                elif child.lemma_ == \"low\":\n",
    "                    return \"low\"\n",
    "            return \"medium\" #if unknown, use medium\n",
    "\n",
    "        else:\n",
    "            for child in word.children:\n",
    "                if child.like_num:\n",
    "                    childval = eval(child.text)\n",
    "                    if match == \"celsius\" or match == \"c\":\n",
    "                        if childval > 175:\n",
    "                            return \"very high\"\n",
    "                        elif childval > 100:\n",
    "                            return \"high\"\n",
    "                        elif childval > 80:\n",
    "                            return \"medium\"\n",
    "                        elif childval > 25:\n",
    "                            return \"low\"\n",
    "                        else:\n",
    "                            return \"no\"\n",
    "                    elif match == \"fahrenheit\" or match == \"f\":\n",
    "                        if childval > 350:\n",
    "                            return \"very high\"\n",
    "                        elif childval > 210:\n",
    "                            return \"high\"\n",
    "                        elif childval > 180:\n",
    "                            return \"medium\"\n",
    "                        elif childval > 77:\n",
    "                            return \"low\"\n",
    "                        else:\n",
    "                            return \"no\"    \n",
    "    return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    g = nx.DiGraph()\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_instruction_step(sent, g, i, lastnode, ingredients_set):\n",
    "    # i stands for step\n",
    "    addTempNode = False\n",
    "    temp_node = {\"type\": \"heat\", \"label\": \"no\"}\n",
    "    list_of_source_nodes = []\n",
    "   \n",
    "    for word in sent:\n",
    "        # check for new ingredients in flow\n",
    "        match = has_match(word.lemma_, ingredients_set)\n",
    "        if match:\n",
    "            if g.has_node(match) != True:\n",
    "                list_of_source_nodes.append(match)\n",
    "        else:\n",
    "            heat_amount = has_heat(word)\n",
    "            if heat_amount != None:\n",
    "                temp_node[\"label\"] = heat_amount\n",
    "                addTempNode = True\n",
    "    \n",
    "    # check if new temperature node is needed\n",
    "    if addTempNode == True:\n",
    "        g.add_node(i, attr_dict=temp_node)\n",
    "        newnode = i\n",
    "        if (lastnode != None):\n",
    "            g.add_edge(lastnode, newnode)\n",
    "        lastnode = newnode    \n",
    "    if len(list_of_source_nodes) > 0:\n",
    "        if addTempNode == False: \n",
    "            if (lastnode != None):\n",
    "                for node in g.nodes(data=True):\n",
    "                    if node[0] == lastnode:\n",
    "                        if node[1][\"type\"] == \"heat\":\n",
    "                            temp_node[\"label\"] = node[1][\"label\"]\n",
    "                        break\n",
    "                g.add_node(i, attr_dict=temp_node)\n",
    "                newnode = i\n",
    "                g.add_edge(lastnode, newnode)\n",
    "            else:\n",
    "                g.add_node(i, attr_dict=temp_node)\n",
    "                newnode = i\n",
    "            lastnode = newnode\n",
    "        \n",
    "        for node in list_of_source_nodes:\n",
    "            g.add_node(node, attr_dict={\"type\": \"ingredient\", \"label\": node, \"ingredient\": ingredients_set[node]})\n",
    "            g.add_edge(node, lastnode)\n",
    "\n",
    "    return lastnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addDoneNode(g, lastnode):\n",
    "    g.add_node(\"done\", attr_dict={\"type\": \"done\", \"label\": \"done\"})\n",
    "    g.add_edge(lastnode, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_instruction_steps(text, ingredients_set):\n",
    "    # some dumb preprocessing\n",
    "    text = text.replace(u\"째F\", u\" F \")\n",
    "    text = text.replace(u\"째f\", u\" f \")\n",
    "    text = text.replace(u\"째C\", u\" C \")\n",
    "    text = text.replace(u\"째c\", u\" c \")\n",
    "    text = text.strip()\n",
    "\n",
    "    doc = nlp(text)\n",
    "    g = create_graph()\n",
    "    i = 0\n",
    "    currnode = None\n",
    "    for sent in doc.sents:\n",
    "        currnode = get_instruction_step(sent, g, i, currnode, ingredients_set)\n",
    "        i += 1\n",
    "    addDoneNode(g, currnode)\n",
    "    return json_graph.node_link_data(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_formatted_recipe(url):\n",
    "    recipe = {\"source\": url}\n",
    "    page = fetch_url(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    title = soup.select(\".title-source h1\")\n",
    "    assert len(title) == 1\n",
    "    recipe[\"title\"] = title[0].string.strip()\n",
    "    \n",
    "    rating = soup.select(\".rating\")\n",
    "    assert len(rating) == 1\n",
    "    recipe[\"rating\"] = eval(str(rating[0].string))\n",
    "    \n",
    "    rating_count = soup.select(\".reviews-count\")\n",
    "    assert len(rating_count) == 1\n",
    "    recipe[\"rating_count\"] = eval(str(rating_count[0].string))\n",
    "    \n",
    "    make_again_rating = soup.select(\".prepare-again-rating span\")\n",
    "    assert len(make_again_rating) == 1\n",
    "    recipe[\"make_again_rating\"] = eval(str(make_again_rating[0].string.replace(\"%\", \"/100.0\")))\n",
    "    \n",
    "    ingredients_text = soup.select(\".ingredient-groups\")\n",
    "    assert len(ingredients_text) == 1\n",
    "    ingredients_list = get_ingredient_list(\"\\n\".join(ingredients_text[0].findAll(text=True)))\n",
    "    recipe[\"ingredients\"] = ingredients_list\n",
    "    \n",
    "    steps = soup.select(\".preparation-groups\")\n",
    "    assert len(steps) == 1\n",
    "    steps_text = \"\".join(steps[0].findAll(text=True))\n",
    "    recipe[\"steps\"] = get_instruction_steps(steps_text, ingredients_list)\n",
    "\n",
    "    return recipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
